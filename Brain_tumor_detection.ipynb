{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "VM9HqXtwxSo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "Ay2u0knoxZT2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting drive"
      ],
      "metadata": {
        "id": "htRityiMcLk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDhaCHF1cTre",
        "outputId": "bf7adebb-32ed-4aa6-970d-5e3ae346c560"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Dataset"
      ],
      "metadata": {
        "id": "1JwYX-jnU_vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sr=r\"/content/drive/MyDrive/brain_tumor_dataset/\"\n",
        "root_dir = r'/content/drive/MyDrive/brain_tumor_dataset/'\n",
        "classes_dir = ['yes','no']\n",
        "\n",
        "test_ratio = 0.20\n",
        "#create folder train and test , every folder have two subfolder -->(yes and no)\n",
        "for cls in classes_dir:\n",
        "    os.makedirs(root_dir +'train/' + cls)\n",
        "    os.makedirs(root_dir +'test/' + cls)\n",
        "\n",
        "import tqdm\n",
        "def call2(filen):#yes\n",
        "    #define the src folder\n",
        "    src = os.path.join(sr,filen)\n",
        "    #read the src folder\n",
        "    allFileNames = os.listdir(src)\n",
        "    #randomize the files names\n",
        "    np.random.shuffle(allFileNames)\n",
        "    #split the files in train and test\n",
        "    train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
        "                                                              [int(len(allFileNames)* (1 - test_ratio))])\n",
        "\n",
        "    #add the full url\n",
        "    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
        "    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
        "\n",
        "    print(\"*****************************\")\n",
        "    print('Total images: ', len(allFileNames))\n",
        "    print('Training: ', len(train_FileNames))\n",
        "    print('Testing: ', len(test_FileNames))\n",
        "    print(\"*****************************\")\n",
        "\n",
        "    #copy the train and test files in corresponding folder\n",
        "    for name in tqdm.tqdm(train_FileNames):\n",
        "        try:\n",
        "            shutil.copy(name, root_dir +'train/'+filen+'/' )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for name in tqdm.tqdm(test_FileNames):\n",
        "        #if any error it ignores this file.\n",
        "        try:\n",
        "            shutil.copy(name, root_dir +'test/'+filen+'/')\n",
        "        except:\n",
        "            pass\n",
        "    print(\"Copying Done!\")"
      ],
      "metadata": {
        "id": "CBQjzXS8VFqK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in classes_dir:\n",
        "  # we called every class folder from here. --> accident ,noaccident\n",
        "  call2(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K-9fHMxlJEi",
        "outputId": "4241d080-214e-48a9-b22d-72daa5e8ef4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************\n",
            "Total images:  155\n",
            "Training:  124\n",
            "Testing:  31\n",
            "*****************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 124/124 [00:03<00:00, 33.50it/s]\n",
            "100%|██████████| 31/31 [00:00<00:00, 42.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying Done!\n",
            "*****************************\n",
            "Total images:  98\n",
            "Training:  78\n",
            "Testing:  20\n",
            "*****************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78/78 [00:03<00:00, 25.98it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 82.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "yFiy5ZYDl6tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(180, 180, 3),\n",
        "    pooling='max',\n",
        "    classes=2,\n",
        ")\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "6KMJ3OjKl9Kh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet_model.summary()"
      ],
      "metadata": {
        "id": "94ezGkommVOY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0CGTmxB01v7E"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height,img_width=180,180\n",
        "batch_size=32\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  sr,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  sr,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8QvAHSMsTqo",
        "outputId": "3b391dbf-2d53-45f2-aec7-c9de5693ef7b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 506 files belonging to 4 classes.\n",
            "Using 405 files for training.\n",
            "Found 506 files belonging to 4 classes.\n",
            "Using 101 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = resnet_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo-EboFA0HmI",
        "outputId": "e49eb89c-2356-462d-9734-86fe4542a81e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 92s 7s/step - loss: -449.9695 - accuracy: 0.1012 - val_loss: -991.4415 - val_accuracy: 0.1089\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 83s 6s/step - loss: -1756.9133 - accuracy: 0.0988 - val_loss: -2466.3789 - val_accuracy: 0.1089\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 85s 6s/step - loss: -3583.4629 - accuracy: 0.0988 - val_loss: -4558.7212 - val_accuracy: 0.1089\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 82s 6s/step - loss: -6202.0029 - accuracy: 0.0988 - val_loss: -7378.2969 - val_accuracy: 0.1089\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 90s 7s/step - loss: -9559.4756 - accuracy: 0.0988 - val_loss: -11000.0732 - val_accuracy: 0.1089\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 85s 6s/step - loss: -13748.3936 - accuracy: 0.0988 - val_loss: -15537.8086 - val_accuracy: 0.1089\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 85s 7s/step - loss: -19160.7305 - accuracy: 0.0988 - val_loss: -20734.5000 - val_accuracy: 0.1089\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 84s 6s/step - loss: -25310.5059 - accuracy: 0.0988 - val_loss: -27091.8496 - val_accuracy: 0.1089\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 81s 6s/step - loss: -32559.1895 - accuracy: 0.0988 - val_loss: -34433.6094 - val_accuracy: 0.1089\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 89s 7s/step - loss: -40771.0430 - accuracy: 0.0988 - val_loss: -42913.6367 - val_accuracy: 0.1089\n"
          ]
        }
      ]
    }
  ]
}